Warning: 100 points required, but 256 points sampled.
Warning: 10000 points required, but 25600 points sampled.
Compiling model...
'compile' took 3.323251 s

Training model...

Step      Train loss                                  Test loss                                   Test metric
0         [1.08e-01, 5.47e-01, 5.60e-01, 5.47e-02]    [9.06e-02, 5.47e-01, 5.60e-01, 5.47e-02]    []

Best model at step 0:
  train loss: 1.27e+00
  test loss: 1.25e+00
  test metric: []

'train' took 41.243360 s

Compiling model...
'compile' took 0.005487 s

Training model...

Step      Train loss                                  Test loss                                   Test metric
0         [4.00e+00, 4.00e+00, 4.00e+00, 4.00e+00]    [3.34e+00, 4.00e+00, 4.00e+00, 4.00e+00]    []
100       [5.79e-01, 1.51e+00, 3.33e+00, 3.81e+00]    [2.58e-01, 1.51e+00, 3.33e+00, 3.81e+00]    []
200       [5.11e-01, 1.47e+00, 1.80e+00, 1.18e+00]    [1.84e-01, 1.47e+00, 1.80e+00, 1.18e+00]    []
300       [4.10e-01, 1.44e+00, 1.56e+00, 9.91e-01]    [2.97e-01, 1.44e+00, 1.56e+00, 9.91e-01]    []
400       [8.38e-01, 1.46e+00, 1.38e+00, 8.09e-01]    [3.82e-01, 1.46e+00, 1.38e+00, 8.09e-01]    []
500       [2.29e-01, 1.41e+00, 1.20e+00, 8.38e-01]    [9.49e-02, 1.41e+00, 1.20e+00, 8.38e-01]    []
600       [2.13e-01, 1.40e+00, 1.06e+00, 7.78e-01]    [8.55e-02, 1.40e+00, 1.06e+00, 7.78e-01]    []
700       [3.12e-01, 1.40e+00, 9.84e-01, 6.99e-01]    [1.20e-01, 1.40e+00, 9.84e-01, 6.99e-01]    []
800       [1.72e-01, 1.39e+00, 9.39e-01, 6.56e-01]    [7.85e-02, 1.39e+00, 9.39e-01, 6.56e-01]    []
900       [1.70e-01, 1.39e+00, 8.98e-01, 6.06e-01]    [1.19e-01, 1.39e+00, 8.98e-01, 6.06e-01]    []
1000      [1.36e-01, 1.39e+00, 8.70e-01, 5.30e-01]    [6.04e-02, 1.39e+00, 8.70e-01, 5.30e-01]    []
1100      [1.16e-01, 1.39e+00, 8.41e-01, 4.43e-01]    [5.26e-02, 1.39e+00, 8.41e-01, 4.43e-01]    []
1200      [9.93e-02, 1.36e+00, 8.16e-01, 3.37e-01]    [4.25e-02, 1.36e+00, 8.16e-01, 3.37e-01]    []
1300      [9.13e-02, 1.33e+00, 7.93e-01, 2.48e-01]    [3.63e-02, 1.33e+00, 7.93e-01, 2.48e-01]    []
1400      [1.21e-01, 1.31e+00, 7.73e-01, 2.01e-01]    [8.28e-02, 1.31e+00, 7.73e-01, 2.01e-01]    []
1500      [6.49e-02, 1.29e+00, 7.54e-01, 1.69e-01]    [2.39e-02, 1.29e+00, 7.54e-01, 1.69e-01]    []
1600      [1.24e-01, 1.28e+00, 7.36e-01, 1.53e-01]    [1.00e-01, 1.28e+00, 7.36e-01, 1.53e-01]    []
1700      [5.32e-02, 1.27e+00, 7.22e-01, 1.37e-01]    [1.84e-02, 1.27e+00, 7.22e-01, 1.37e-01]    []
1800      [4.65e-02, 1.26e+00, 7.04e-01, 1.26e-01]    [1.74e-02, 1.26e+00, 7.04e-01, 1.26e-01]    []
1900      [4.39e-02, 1.26e+00, 6.87e-01, 1.20e-01]    [1.70e-02, 1.26e+00, 6.87e-01, 1.20e-01]    []
2000      [4.11e-02, 1.25e+00, 6.73e-01, 1.15e-01]    [1.57e-02, 1.25e+00, 6.73e-01, 1.15e-01]    []
2100      [3.88e-02, 1.25e+00, 6.58e-01, 1.11e-01]    [1.60e-02, 1.25e+00, 6.58e-01, 1.11e-01]    []
2200      [6.83e-02, 1.25e+00, 6.46e-01, 1.08e-01]    [5.28e-02, 1.25e+00, 6.46e-01, 1.08e-01]    []
2300      [3.59e-02, 1.25e+00, 6.34e-01, 1.06e-01]    [1.46e-02, 1.25e+00, 6.34e-01, 1.06e-01]    []
2400      [3.38e-02, 1.25e+00, 6.23e-01, 1.03e-01]    [1.48e-02, 1.25e+00, 6.23e-01, 1.03e-01]    []
2500      [3.29e-02, 1.24e+00, 6.16e-01, 1.00e-01]    [1.57e-02, 1.24e+00, 6.16e-01, 1.00e-01]    []
2600      [3.13e-02, 1.24e+00, 6.10e-01, 9.81e-02]    [1.46e-02, 1.24e+00, 6.10e-01, 9.81e-02]    []
2700      [3.92e-02, 1.24e+00, 6.06e-01, 9.53e-02]    [2.40e-02, 1.24e+00, 6.06e-01, 9.53e-02]    []
2800      [2.82e-02, 1.24e+00, 6.01e-01, 9.34e-02]    [1.37e-02, 1.24e+00, 6.01e-01, 9.34e-02]    []
2900      [2.69e-02, 1.24e+00, 5.98e-01, 9.24e-02]    [1.30e-02, 1.24e+00, 5.98e-01, 9.24e-02]    []
3000      [2.63e-02, 1.24e+00, 5.96e-01, 8.99e-02]    [1.27e-02, 1.24e+00, 5.96e-01, 8.99e-02]    []

Best model at step 0:
  train loss: 1.27e+00
  test loss: 1.25e+00
  test metric: []

Epoch 3000: saving model to ./tests/models/BioHeat_PINNs_date_time_20240711_212139/adam-3000.pt ...

'train' took 38506.280104 s

[2024-07-12 10:24:25,893][matplotlib.mathtext][INFO] - Substituting symbol L from STIXNonUnicode
[2024-07-12 10:24:25,925][matplotlib.mathtext][INFO] - Substituting symbol L from STIXNonUnicode
[2024-07-12 10:24:25,947][matplotlib.mathtext][INFO] - Substituting symbol L from STIXNonUnicode
[2024-07-12 10:24:25,970][matplotlib.mathtext][INFO] - Substituting symbol L from STIXNonUnicode
Generated Xobs shape: (2541, 5)
Unique e[:, 0] (la): 11, Unique e[:, 1] (le): 11
theta_true.size: 2541, theta_pred.size: 2541
Expected size: 121
Saving the image: ./tests/figures/BioHeat_PINNs_date_time_20240711_212139/l2_tf.png
xtr shape: (11,), final shape: (231, 4)
