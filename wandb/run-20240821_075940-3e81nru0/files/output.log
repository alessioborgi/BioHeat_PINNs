Layer size is:  [3, 50, 50, 1]
Compiling model...
'compile' took 2.725599 s

Training model...

Warning: Rectangle boundary_normal called on vertices. You may use PDE(..., exclusions=...) to exclude the vertices.
Warning: Rectangle boundary_normal called on vertices. You may use PDE(..., exclusions=...) to exclude the vertices.
Step      Train loss                                                      Test loss                                                       Test metric
0         [5.71e+00, 0.00e+00, 6.75e-01, 4.50e-01, 3.27e-01, 6.01e-02]    [5.68e+00, 0.00e+00, 6.75e-01, 4.50e-01, 3.27e-01, 6.01e-02]    []

Best model at step 0:
  train loss: 7.22e+00
  test loss: 7.19e+00
  test metric: []

'train' took 3.717541 s

Compiling model...
'compile' took 0.001374 s

Training model...

Step      Train loss                                                      Test loss                                                       Test metric
0         [6.00e+00, 0.00e+00, 6.00e+00, 6.00e+00, 6.00e+00, 6.00e+00]    [5.97e+00, 0.00e+00, 6.00e+00, 6.00e+00, 6.00e+00, 6.00e+00]    []
10        [8.72e-01, 0.00e+00, 1.28e+00, 8.66e-01, 8.51e-01, 3.39e-01]    [8.84e-01, 0.00e+00, 1.28e+00, 8.66e-01, 8.51e-01, 3.39e-01]    []
20        [2.39e-01, 0.00e+00, 1.14e+00, 8.82e-02, 7.29e-02, 4.65e-02]    [2.35e-01, 0.00e+00, 1.14e+00, 8.82e-02, 7.29e-02, 4.65e-02]    []
25        [1.75e-01, 0.00e+00, 1.24e+00, 6.15e-02, 2.03e-01, 2.07e-01]    [1.62e-01, 0.00e+00, 1.24e+00, 6.15e-02, 2.03e-01, 2.07e-01]    []

Best model at step 20:
  train loss: 1.59e+00
  test loss: 1.59e+00
  test metric: []

Epoch 25: saving model to ./tests/models/BioHeat_PINNs_date_time_20240821_075938/adam-25.pt ...

'train' took 81.541438 s

Compiling model...
'compile' took 0.002394 s

Training model...

Step      Train loss                                                      Test loss                                                       Test metric
25        [1.67e-01, 0.00e+00, 1.40e-01, 4.61e-03, 1.11e-02, 2.08e-03]    [1.54e-01, 0.00e+00, 1.40e-01, 4.61e-03, 1.11e-02, 2.08e-03]    []

Best model at step 25:
  train loss: 3.24e-01
  test loss: 3.11e-01
  test metric: []

'train' took 3.631879 s
/working_dir/src/train.py:68: RuntimeWarning: divide by zero encountered in divide
  loss_weights = len(initial_losses) / initial_losses + 0.00001

Compiling model...
'compile' took 0.001961 s

Training model...

Step      Train loss                                                      Test loss                                                       Test metric
25        [1.75e-01, nan, 1.24e+00, 6.15e-02, 2.03e-01, 2.07e-01]         [1.62e-01, nan, 1.24e+00, 6.15e-02, 2.03e-01, 2.07e-01]         []
Traceback (most recent call last):
  File "/working_dir/./src/tuning.py", line 200, in <module>
    main()
  File "/opt/conda/lib/python3.10/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/opt/conda/lib/python3.10/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/opt/conda/lib/python3.10/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/opt/conda/lib/python3.10/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/opt/conda/lib/python3.10/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/opt/conda/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/opt/conda/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/working_dir/./src/tuning.py", line 106, in main
    model, metrics = train.single_observer(prj, cfg.run, "0", cfg)
  File "/working_dir/src/train.py", line 101, in single_observer
    # Rest of the function continues as before
  File "/working_dir/src/train.py", line 73, in train_model
  File "/working_dir/src/train.py", line 124, in train_and_save_model
  File "/opt/conda/lib/python3.10/site-packages/deepxde/utils/internal.py", line 22, in wrapper
    result = f(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/model.py", line 651, in train
    self._train_pytorch_lbfgs()
  File "/opt/conda/lib/python3.10/site-packages/deepxde/model.py", line 773, in _train_pytorch_lbfgs
    self._train_step(
  File "/opt/conda/lib/python3.10/site-packages/deepxde/model.py", line 567, in _train_step
    self.train_step(inputs, targets, auxiliary_vars)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/model.py", line 364, in train_step
    self.opt.step(closure)
  File "/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/optim/lbfgs.py", line 428, in step
    loss, flat_grad, t, ls_func_evals = _strong_wolfe(
  File "/opt/conda/lib/python3.10/site-packages/torch/optim/lbfgs.py", line 99, in _strong_wolfe
    f_new, g_new = obj_func(x, t, d)
  File "/opt/conda/lib/python3.10/site-packages/torch/optim/lbfgs.py", line 426, in obj_func
    return self._directional_evaluate(closure, x, t, d)
  File "/opt/conda/lib/python3.10/site-packages/torch/optim/lbfgs.py", line 280, in _directional_evaluate
    loss = float(closure())
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/model.py", line 361, in closure
    total_loss.backward()
  File "/opt/conda/lib/python3.10/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
