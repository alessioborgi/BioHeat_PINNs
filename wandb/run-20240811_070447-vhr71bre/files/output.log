Layer size is:  [3, 50, 50, 1]
Compiling model...
Error executing job with overrides: []
Traceback (most recent call last):
  File "/working_dir/./src/tuning.py", line 98, in main
    model, metrics = train.single_observer(prj, cfg.run, "0", cfg)
  File "/working_dir/src/train.py", line 109, in single_observer
    mo = train_model(run, cfg)
  File "/working_dir/src/train.py", line 46, in train_model
    mm = pde.create_nbho(name, cfg)
  File "/working_dir/src/pde.py", line 247, in create_nbho
    initial_losses = train.get_initial_loss(model)
  File "/working_dir/src/train.py", line 154, in get_initial_loss
    model.compile("nadam", lr=0.001)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/utils/internal.py", line 22, in wrapper
    result = f(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/model.py", line 141, in compile
    self._compile_pytorch(lr, loss_fn, decay)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/model.py", line 338, in _compile_pytorch
    self.opt, self.lr_scheduler = optimizers.get(
  File "/opt/conda/lib/python3.10/site-packages/deepxde/optimizers/pytorch/optimizers.py", line 52, in get
    raise NotImplementedError(
NotImplementedError: nadam to be implemented for backend pytorch.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
