Warning: 100 points required, but 256 points sampled.
Warning: 10000 points required, but 25600 points sampled.
Compiling model...
'compile' took 2.751602 s

Training model...

Step      Train loss                                  Test loss                                   Test metric
0         [6.44e-01, 3.28e-01, 4.63e-01, 1.32e-01]    [3.97e-01, 3.28e-01, 4.63e-01, 1.32e-01]    []

Best model at step 0:
  train loss: 1.57e+00
  test loss: 1.32e+00
  test metric: []

'train' took 5.186904 s

Compiling model...
'compile' took 0.001286 s

Training model...

Step      Train loss                                  Test loss                                   Test metric
0         [4.00e+00, 4.00e+00, 4.00e+00, 4.00e+00]    [2.47e+00, 4.00e+00, 4.00e+00, 4.00e+00]    []
100       [5.81e-01, 2.33e+00, 3.51e+00, 1.93e+00]    [3.78e-01, 2.33e+00, 3.51e+00, 1.93e+00]    []
200       [3.52e-01, 2.17e+00, 2.55e+00, 1.61e+00]    [2.01e-01, 2.17e+00, 2.55e+00, 1.61e+00]    []
300       [2.76e-01, 2.21e+00, 2.06e+00, 9.66e-01]    [1.24e-01, 2.21e+00, 2.06e+00, 9.66e-01]    []
400       [2.63e-01, 2.16e+00, 1.77e+00, 5.79e-01]    [1.08e-01, 2.16e+00, 1.77e+00, 5.79e-01]    []
500       [2.35e-01, 2.13e+00, 1.43e+00, 4.47e-01]    [9.82e-02, 2.13e+00, 1.43e+00, 4.47e-01]    []
600       [2.03e-01, 2.11e+00, 1.17e+00, 3.99e-01]    [9.68e-02, 2.11e+00, 1.17e+00, 3.99e-01]    []
700       [1.85e-01, 2.10e+00, 1.03e+00, 3.78e-01]    [9.69e-02, 2.10e+00, 1.03e+00, 3.78e-01]    []
800       [1.63e-01, 2.09e+00, 9.72e-01, 3.51e-01]    [8.99e-02, 2.09e+00, 9.72e-01, 3.51e-01]    []
900       [1.41e-01, 2.09e+00, 9.29e-01, 3.23e-01]    [8.38e-02, 2.09e+00, 9.29e-01, 3.23e-01]    []
1000      [1.32e-01, 2.08e+00, 8.88e-01, 2.99e-01]    [7.81e-02, 2.08e+00, 8.88e-01, 2.99e-01]    []
1100      [1.30e-01, 2.08e+00, 8.51e-01, 2.76e-01]    [7.40e-02, 2.08e+00, 8.51e-01, 2.76e-01]    []
1200      [1.21e-01, 2.08e+00, 8.21e-01, 2.75e-01]    [6.99e-02, 2.08e+00, 8.21e-01, 2.75e-01]    []
1300      [1.20e-01, 2.08e+00, 7.96e-01, 2.56e-01]    [6.57e-02, 2.08e+00, 7.96e-01, 2.56e-01]    []
1400      [1.15e-01, 2.08e+00, 7.80e-01, 2.55e-01]    [6.40e-02, 2.08e+00, 7.80e-01, 2.55e-01]    []
1500      [1.11e-01, 2.08e+00, 7.68e-01, 2.45e-01]    [6.09e-02, 2.08e+00, 7.68e-01, 2.45e-01]    []
1600      [1.06e-01, 2.08e+00, 7.58e-01, 2.36e-01]    [5.95e-02, 2.08e+00, 7.58e-01, 2.36e-01]    []
1700      [1.07e-01, 2.08e+00, 7.54e-01, 2.26e-01]    [5.85e-02, 2.08e+00, 7.54e-01, 2.26e-01]    []
1800      [1.14e-01, 2.09e+00, 7.51e-01, 2.11e-01]    [5.90e-02, 2.09e+00, 7.51e-01, 2.11e-01]    []
1900      [1.08e-01, 2.08e+00, 7.47e-01, 2.12e-01]    [5.77e-02, 2.08e+00, 7.47e-01, 2.12e-01]    []
2000      [1.05e-01, 2.08e+00, 7.45e-01, 2.05e-01]    [5.61e-02, 2.08e+00, 7.45e-01, 2.05e-01]    []
2100      [1.03e-01, 2.08e+00, 7.41e-01, 2.00e-01]    [5.27e-02, 2.08e+00, 7.41e-01, 2.00e-01]    []
2200      [1.02e-01, 2.08e+00, 7.34e-01, 1.97e-01]    [6.13e-02, 2.08e+00, 7.34e-01, 1.97e-01]    []
2300      [9.91e-02, 2.08e+00, 7.30e-01, 1.76e-01]    [5.01e-02, 2.08e+00, 7.30e-01, 1.76e-01]    []
2400      [1.04e-01, 2.08e+00, 7.28e-01, 1.62e-01]    [4.78e-02, 2.08e+00, 7.28e-01, 1.62e-01]    []
2500      [9.58e-02, 2.07e+00, 7.27e-01, 1.56e-01]    [4.45e-02, 2.07e+00, 7.27e-01, 1.56e-01]    []
2600      [9.02e-02, 2.07e+00, 7.26e-01, 1.48e-01]    [4.03e-02, 2.07e+00, 7.26e-01, 1.48e-01]    []
2700      [9.45e-02, 2.08e+00, 7.23e-01, 1.37e-01]    [3.80e-02, 2.08e+00, 7.23e-01, 1.37e-01]    []
2800      [8.07e-02, 2.07e+00, 7.21e-01, 1.32e-01]    [3.53e-02, 2.07e+00, 7.21e-01, 1.32e-01]    []
2900      [8.01e-02, 2.07e+00, 7.18e-01, 1.34e-01]    [4.42e-02, 2.07e+00, 7.18e-01, 1.34e-01]    []
3000      [7.42e-02, 2.07e+00, 7.17e-01, 1.18e-01]    [3.13e-02, 2.07e+00, 7.17e-01, 1.18e-01]    []

Best model at step 0:
  train loss: 1.57e+00
  test loss: 1.32e+00
  test metric: []

Epoch 3000: saving model to ./tests/models/BioHeat_PINNs_date_time_20240711_195409/adam-3000.pt ...

'train' took 4854.736266 s

[2024-07-11 21:15:20,101][matplotlib.mathtext][INFO] - Substituting symbol L from STIXNonUnicode
[2024-07-11 21:15:20,130][matplotlib.mathtext][INFO] - Substituting symbol L from STIXNonUnicode
[2024-07-11 21:15:20,153][matplotlib.mathtext][INFO] - Substituting symbol L from STIXNonUnicode
[2024-07-11 21:15:20,177][matplotlib.mathtext][INFO] - Substituting symbol L from STIXNonUnicode
Generated Xobs shape: (2541, 5)
Unique e[:, 0] (la): 11, Unique e[:, 1] (le): 11
theta_true.size: 2541, theta_pred.size: 2541
Expected size: 121
Saving the image: ./tests/figures/BioHeat_PINNs_date_time_20240711_195409/l2_tf.png
xtr shape: (11,), final shape: (231, 4)
