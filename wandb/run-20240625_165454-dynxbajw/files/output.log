Warning: 100 points required, but 125 points sampled.
Warning: 10000 points required, but 12500 points sampled.
Compiling model...
'compile' took 1.670313 s
Training model...
Step      Train loss                        Test loss                         Test metric
0         [1.80e-01, 1.48e+03, 1.33e-01]    [1.76e-01, 1.48e+03, 1.33e-01]    []
Best model at step 0:
  train loss: 1.48e+03
  test loss: 1.48e+03
  test metric: []
'train' took 1.881421 s
Compiling model...
'compile' took 0.001265 s
Training model...
Step      Train loss                        Test loss                         Test metric
0         [3.00e+00, 3.00e+00, 3.00e+00]    [2.94e+00, 3.00e+00, 3.00e+00]    []
Traceback (most recent call last):
  File "/working_dir/./src/main.py", line 39, in <module>
    utils.single_observer(prj, run, "0")
  File "/working_dir/src/utils.py", line 502, in single_observer
    mo = train_model(name_run)
  File "/working_dir/src/utils.py", line 329, in train_model
    losshistory, train_state = train_and_save_model(mm, epochs, callbacks, "adam")
  File "/working_dir/src/utils.py", line 336, in train_and_save_model
    losshistory, train_state = model.train(
  File "/opt/conda/lib/python3.10/site-packages/deepxde/utils/internal.py", line 22, in wrapper
    result = f(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/model.py", line 650, in train
    self._train_sgd(iterations, display_every)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/model.py", line 668, in _train_sgd
    self._train_step(
  File "/opt/conda/lib/python3.10/site-packages/deepxde/model.py", line 562, in _train_step
    self.train_step(inputs, targets, auxiliary_vars)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/model.py", line 362, in train_step
    self.opt.step(closure)
  File "/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py", line 146, in step
    loss = closure()
  File "/opt/conda/lib/python3.10/site-packages/deepxde/model.py", line 356, in closure
    losses = outputs_losses_train(inputs, targets, auxiliary_vars)[1]
  File "/opt/conda/lib/python3.10/site-packages/deepxde/model.py", line 320, in outputs_losses_train
    return outputs_losses(
  File "/opt/conda/lib/python3.10/site-packages/deepxde/model.py", line 308, in outputs_losses
    losses = losses_fn(targets, outputs_, loss_fn, inputs, self, aux=aux)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/data/data.py", line 13, in losses_train
    return self.losses(targets, outputs, loss_fn, inputs, model, aux=aux)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/data/pde.py", line 146, in losses
    f = self.pde(inputs, outputs_pde)
  File "/working_dir/src/utils.py", line 219, in pde
    dy_t = dde.grad.jacobian(y, x, i=0, j=3)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/gradients/gradients.py", line 34, in jacobian
    return gradients_reverse.jacobian(ys, xs, i=i, j=j)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/gradients/gradients_reverse.py", line 73, in jacobian
    return jacobian._Jacobians(ys, xs, i=i, j=j)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/gradients/jacobian.py", line 128, in __call__
    return self.Js[key](i, j)
  File "/opt/conda/lib/python3.10/site-packages/deepxde/gradients/gradients_reverse.py", line 29, in __call__
    self.J[i] = torch.autograd.grad(
  File "/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py", line 411, in grad
    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt